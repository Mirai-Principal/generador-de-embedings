{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "3UsUwF1qu9yl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Crear capa de vectorización de texto\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=1000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=5\n",
        ")\n",
        "\n",
        "# 2. Preparar un \"vocabulario - corpus\" con algunos ejemplos\n",
        "text_data = tf.constant([\n",
        "    \"hola mundo\",\n",
        "    \"buenos días que haces\",\n",
        "    \"hola amigo\",\n",
        "    \"mundo abierto\"\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "mtNWPaUht2mM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "la línea token_ids = vectorize_layer(input_text) está efectivamente obteniendo los IDs del input_text basándose en el vocabulario aprendido del text_data. Es como una \"traducción\" de palabras a números utilizando el diccionario creado a partir del corpus."
      ],
      "metadata": {
        "id": "px8FAoSluNpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. entrenar o Adaptar la capa a esos textos - vectoriza los tokens del corpus\n",
        "vectorize_layer.adapt(text_data)\n",
        "\n",
        "# 4. Vectorizar tu entrada - vectoriza los tokens de entrada\n",
        "input_text = tf.constant([\"hola mundo\"])\n",
        "token_ids = vectorize_layer(input_text)"
      ],
      "metadata": {
        "id": "k29Ai_v-t9GR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZweLev2u783",
        "outputId": "32a68b44-f183-4726-a560-e4d5d005aa8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto: [b'hola mundo']\n",
            "Token IDs: [[3 2 0 0 0]]\n",
            "tf.Tensor(b'mundo abierto', shape=(), dtype=string)\n",
            "tf.Tensor(b'hola amigo', shape=(), dtype=string)\n",
            "tf.Tensor(b'hola mundo', shape=(), dtype=string)\n",
            "Embeddings:\n",
            " [[[ 0.04369533  0.01390279 -0.01963254  0.00200937]\n",
            "  [-0.0456666   0.03178049 -0.02291701  0.02356335]\n",
            "  [-0.0156853   0.0494352   0.01687149  0.00582154]\n",
            "  [-0.0156853   0.0494352   0.01687149  0.00582154]\n",
            "  [-0.0156853   0.0494352   0.01687149  0.00582154]]]\n"
          ]
        }
      ],
      "source": [
        "# 5. Crear la capa de embedding (dim 4 por ejemplo) - dimension de los embedings\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=1000, output_dim=4)\n",
        "\n",
        "# 6. Obtener los embeddings\n",
        "embedded_output = embedding_layer(token_ids)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Texto:\", input_text.numpy())\n",
        "print(\"Token IDs:\", token_ids.numpy())\n",
        "\n",
        "#muestra conde aparece los tokens de la frase de entrada en el corpus\n",
        "print(text_data[3])\n",
        "print(text_data[2])\n",
        "print(text_data[0])\n",
        "\n",
        "print(\"Embeddings:\\n\", embedded_output.numpy())\n"
      ]
    }
  ]
}